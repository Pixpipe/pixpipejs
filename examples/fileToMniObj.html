<html>
<head>
  <title>File to MNI OBJ</title>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/88/three.min.js"></script>

  <script src="../dist/pixpipe.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css">
  
  <style>
  
  body {
    
    color: #000;
    font-family:Monospace;
    font-size:13px;
    text-align:center;
    background-color: #ADD;
    margin: 0px;
    overflow: hidden;
  }
  
  #info {
    z-index: 10;
    text-align: left;
    margin: 10px;
    position: fixed;
    top: 0;
    left: 0;
  }
  
  #info code {
    background-color: #8BB;
    line-height: 1.5;
  }
  
  #container {
    z-index: 1;
    position: fixed;
    left: 0;
    right: 0;
    top: 0;
    bottom: 0;
    width: 100vw;
    height: 100vh;
  }
  
  </style>
  
</head>
<body>
  
  <div id="info">
    <h1><a href="https://github.com/Pixpipe/pixpipejs"><span style="color: #ff91d7">Pixpipe</span><span style="color: #FFFFFF">js</span></a></h1>
    <p>
    This does the following :
    <ul>
      <li>open a local MNI OBJ file, using <code>pixpipe.FileToArrayBufferReader</code></li>
      <li>Set the metadata <code>readAsText</code> of the <code>pixpipe.FileToArrayBufferReader</code> to <code>true</code></li>
      <li>redirect the file buffer into a <code>pixpipe.MniObjDecoder</code> to extract mesh data</li>
      <li>get the output as a generique <code>pixpipe.Mesh3D</code> object</li>
      <li>display the mesh using ThreeJS</li>
    </ul>

    </p>


    Open MniOBJ file
    <input type="file" id="fileInput">
    Looking for MNI OBJ sample files? <a href="https://github.com/Pixpipe/mniobjparser/tree/master/examples/data" target="_blank">Look here</a>
    </div>
  </div>
  
  <div id="container"></div>

  

  <script>
  window.onload = function() {

    var fileInput = document.getElementById('fileInput');
    

    // The filter to read image from URL
    var file2Buff = new pixpipe.FileToArrayBufferReader();
    file2Buff.setMetadata("readAsText", true);

    // the image is loaded...
    // here, this = url2ImgFilter
    file2Buff.on("ready", function(){

      var filenames = this.getMetadata("filenames");
      var str = this.getOutput();
      
      var meshParser = new pixpipe.MniObjDecoder();
      meshParser.addInput( str );
      meshParser.update();
      
      var mesh = meshParser.getOutput();
      
      if( mesh ){
        console.log( mesh );
        build3DMeshFromMesh3D( mesh )
      }
      
    });


    // event listener of the file input
    fileInput.addEventListener('change', function(e) {
      var files = e.target.files;
      
      var filenames = {};

      for(var i=0; i<files.length; i++){
        // set the input, an HTML5 File object and a category (ID)
        file2Buff.addInput(files[i], i);
        filenames[i] = files[i].name ;
      }

      file2Buff.setMetadata("filenames", filenames);

      // Perform the reading + conversion ibto ArrayBuffer
      file2Buff.update();
		});







    //*********************************
    
    
    
    
    
    var container;
    var camera, scene, renderer;
    var objectContainer = new THREE.Object3D();

    init();
    animate();


    function init() {
      container = document.getElementById( 'container' );
      camera = new THREE.PerspectiveCamera( 27, window.innerWidth / window.innerHeight, 1, 3500 );
      camera.position.z = 500;
      
      scene = new THREE.Scene();
      scene.fog = new THREE.Fog( 0x050505, 2000, 3500 );
      scene.add( new THREE.AmbientLight( 0x444444 ) );

      var light1 = new THREE.DirectionalLight( 0xffffff, 0.5 );
      light1.position.set( 1, 1, 1 );
      scene.add( light1 );

      var light2 = new THREE.DirectionalLight( 0xffffff, 1.5 );
      light2.position.set( 0, -1, 0 );
      scene.add( light2 );
      scene.add( objectContainer );

      renderer = new THREE.WebGLRenderer( { antialias: true, alpha: true } );
      renderer.setClearColor( 0xffffff, 0 );
      renderer.setPixelRatio( window.devicePixelRatio );
      renderer.setSize( window.innerWidth, window.innerHeight );
      renderer.gammaInput = true;
      renderer.gammaOutput = true;

      container.appendChild( renderer.domElement );
      window.addEventListener( 'resize', onWindowResize, false );
    }
    
    
    function onWindowResize() {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize( window.innerWidth, window.innerHeight );
    }


    function animate() {
      requestAnimationFrame( animate );
      render();
    }


    function render() {
      var time = Date.now() * 0.001;
      objectContainer.rotation.x = time * 0.25;
      objectContainer.rotation.y = time * 0.5;
      renderer.render( scene, camera );
    }


    // build a Threejs Mesh from a Pixpipe Mesh3D
    function build3DMeshFromMesh3D( mesh ){
      var geometry = new THREE.BufferGeometry();

      var positions = mesh.getVertexPositions();
      var indices = mesh.getPolygonFacesOrder();
      var normals = mesh.getPolygonFacesNormals();
      var colors = mesh.getVertexColors();

      geometry.setIndex( new THREE.BufferAttribute( indices, 1 ) );
      geometry.addAttribute( 'position', new THREE.BufferAttribute( positions, 3 ) );
      geometry.addAttribute( 'normal', new THREE.BufferAttribute( normals, 3, true ) );
      geometry.addAttribute( 'color', new THREE.BufferAttribute( colors, 4, true ) );
      geometry.computeBoundingSphere();

      var material = new THREE.MeshPhongMaterial( {
        specular: 0xffffff,
        shininess: 250,
        side: THREE.DoubleSide,
        vertexColors: THREE.VertexColors,
        transparent: true,
        opacity: 0.9,
      } );

      var mesh = new THREE.Mesh( geometry, material );
      objectContainer.add( mesh );
    }









  }
  </script>

</body>
</html>
